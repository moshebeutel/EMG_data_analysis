{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\r\n",
      "Requirement already satisfied: wandb in /home/user/GIT/IdanAchituvPutEMG/venv/lib/python3.8/site-packages (0.12.16)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb --upgrade"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import wandb\n",
    "# wandb.login()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'program': 'trainer.py',\n",
    "    'method': 'bayes'\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metric = {\n",
    "    'name': 'test_avg_acc',\n",
    "    'goal': 'maximize'\n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parameters_dict = {\n",
    "    'optimizer': {\n",
    "        'values': ['sgd']\n",
    "        },\n",
    "    }\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parameters_dict.update({\n",
    "    'lr': {\n",
    "        # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0.005,\n",
    "        'max': 0.02\n",
    "      },\n",
    "    'batch_size': {\n",
    "        # integers between 32 and 256\n",
    "        # with evenly-distributed logarithms\n",
    "        'distribution': 'q_log_uniform_values',\n",
    "        'q': 8,\n",
    "        'min': 256,\n",
    "        'max': 1024,\n",
    "      },\n",
    "    'wd': {\n",
    "        'max': 0.002,\n",
    "        'min': 0.0005,\n",
    "        'distribution': 'uniform'\n",
    "      }\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pprint\n",
    "pprint.pprint(sweep_config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"pytorch-sweeps-trainer_conv3d\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for l in [0.000001, 0.00001, 0.0001]:\n",
    "    for out in [32, 64, 128]:\n",
    "        !python3 trainer.py --lr $l --backbone-output $out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 12:33:00,615 - root - INFO - Logger set. Log level  = INFO\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mmoshebeutel\u001B[0m (\u001B[33memg_diff_priv\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Tracking run with wandb version 0.12.16\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run data is saved locally in \u001B[35m\u001B[1m/home/user/GIT/EMG_data_analysis/p_fed_gp_emg/wandb/run-20220511_123301-yv4yd2kz\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run \u001B[1m`wandb offline`\u001B[0m to turn off syncing.\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Syncing run \u001B[33mrerun_conv3d_putEMG_pFedGP-Full_run_output_lr_0.01\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ‚≠êÔ∏è View project at \u001B[34m\u001B[4mhttps://wandb.ai/emg_diff_priv/emg_gp_moshe\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: üöÄ View run at \u001B[34m\u001B[4mhttps://wandb.ai/emg_diff_priv/emg_gp_moshe/runs/yv4yd2kz\u001B[0m\r\n",
      "Denoising skipped!\r\n",
      "\r\n",
      "Feature extraction skipped!\r\n",
      "\r\n",
      "Reading features for input file:  emg_gestures-03-repeats_long-2018-05-11-11-05-00-695\r\n",
      "Reading features for input file:  emg_gestures-03-repeats_long-2018-06-14-12-32-53-659\r\n",
      "Reading features for input file:  emg_gestures-03-repeats_short-2018-05-11-11-15-21-403\r\n",
      "Reading features for input file:  emg_gestures-03-repeats_short-2018-06-14-12-43-13-875\r\n",
      "Reading features for input file:  emg_gestures-03-sequential-2018-05-11-11-10-50-475\r\n",
      "Reading features for input file:  emg_gestures-03-sequential-2018-06-14-12-38-43-358\r\n",
      "Reading features for input file:  emg_gestures-04-repeats_long-2018-03-28-12-38-01-391\r\n",
      "Reading features for input file:  emg_gestures-04-repeats_long-2018-06-18-15-02-12-970\r\n",
      "Reading features for input file:  emg_gestures-04-repeats_short-2018-03-28-12-53-43-859\r\n",
      "Reading features for input file:  emg_gestures-04-repeats_short-2018-06-18-15-12-34-944\r\n",
      "Reading features for input file:  emg_gestures-04-sequential-2018-03-28-12-49-06-858\r\n",
      "Reading features for input file:  emg_gestures-04-sequential-2018-06-18-15-08-04-934\r\n",
      "Reading features for input file:  emg_gestures-05-repeats_long-2018-04-04-08-32-11-307\r\n",
      "Reading features for input file:  emg_gestures-05-repeats_long-2018-04-23-08-25-01-289\r\n",
      "Reading features for input file:  emg_gestures-05-repeats_short-2018-04-04-08-42-37-751\r\n",
      "Reading features for input file:  emg_gestures-05-repeats_short-2018-04-23-08-35-24-986\r\n",
      "Reading features for input file:  emg_gestures-05-sequential-2018-04-04-08-38-05-065\r\n",
      "Reading features for input file:  emg_gestures-05-sequential-2018-04-23-08-30-53-599\r\n",
      "Reading features for input file:  emg_gestures-06-repeats_long-2018-04-04-14-04-57-907\r\n",
      "Reading features for input file:  emg_gestures-06-repeats_long-2018-04-16-08-36-26-469\r\n",
      "Reading features for input file:  emg_gestures-06-repeats_short-2018-04-04-14-15-20-266\r\n",
      "Reading features for input file:  emg_gestures-06-repeats_short-2018-04-16-08-46-42-440\r\n",
      "Reading features for input file:  emg_gestures-06-sequential-2018-04-04-14-10-48-294\r\n",
      "Reading features for input file:  emg_gestures-06-sequential-2018-04-16-08-42-11-963\r\n",
      "Reading features for input file:  emg_gestures-07-repeats_long-2018-04-04-11-42-19-070\r\n",
      "Reading features for input file:  emg_gestures-07-repeats_long-2018-05-11-12-53-52-085\r\n",
      "Reading features for input file:  emg_gestures-07-repeats_short-2018-04-04-11-52-48-698\r\n",
      "Reading features for input file:  emg_gestures-07-repeats_short-2018-05-11-13-04-19-653\r\n",
      "Reading features for input file:  emg_gestures-07-sequential-2018-04-04-11-48-10-667\r\n",
      "Reading features for input file:  emg_gestures-07-sequential-2018-05-11-12-59-42-080\r\n",
      "2022-05-11 12:33:03,736 - root - INFO - ======================== 24chn =======================\r\n",
      "2022-05-11 12:33:03,736 - root - INFO - ======================== RMS =======================\r\n",
      "2022-05-11 12:33:03,738 - root - INFO - RawEmg3DConvnet(\r\n",
      "  (_conv1): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1))\r\n",
      "  (_pool1): AvgPool3d(kernel_size=(1, 3, 1), stride=(1, 3, 1), padding=0)\r\n",
      "  (_fc1): Linear(in_features=256, out_features=256, bias=True)\r\n",
      "  (_fc2): Linear(in_features=256, out_features=128, bias=True)\r\n",
      "  (_fc3): Linear(in_features=128, out_features=64, bias=True)\r\n",
      "  (_output): Linear(in_features=64, out_features=64, bias=True)\r\n",
      ")\r\n",
      "2022-05-11 12:33:03,738 - root - INFO - Number Parameters: 111424\r\n",
      "  0%|                                                   | 0/300 [00:00<?, ?it/s]2022-05-11 12:33:06,122 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:33:06,122 - root - INFO - Training GP on classes: [6, 7] \r\n",
      "2022-05-11 12:33:06,150 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:06,150 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:06,150 - root - INFO - Loss: 58.41003, Avg. Loss: 0.64187\r\n",
      "2022-05-11 12:33:06,151 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:33:06,152 - root - INFO - Training GP on classes: [0, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:06,462 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:06,463 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:06,463 - root - INFO - Loss: 244.08710, Avg. Loss: 0.35222\r\n",
      "2022-05-11 12:33:06,463 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:33:06,463 - root - INFO - Training GP on classes: [0, 4, 5] \r\n",
      "2022-05-11 12:33:06,639 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:06,639 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:06,639 - root - INFO - Loss: 153.67563, Avg. Loss: 0.25528\r\n",
      "2022-05-11 12:33:06,639 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:33:06,639 - root - INFO - Training GP on classes: [0, 4] \r\n",
      "2022-05-11 12:33:06,790 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:06,790 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:06,791 - root - INFO - Loss: 151.24539, Avg. Loss: 0.27105\r\n",
      "2022-05-11 12:33:06,791 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:33:06,791 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:07,120 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:07,121 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:07,121 - root - INFO - Loss: 279.24829, Avg. Loss: 0.33604\r\n",
      "2022-05-11 12:33:07,121 - root - INFO - No need for training. Class: [3] \r\n",
      "2022-05-11 12:33:07,121 - root - INFO - Training GP on classes: [1, 2, 3] \r\n",
      "2022-05-11 12:33:07,147 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:07,147 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:07,147 - root - INFO - Loss: 30.35398, Avg. Loss: 0.21996\r\n",
      "2022-05-11 12:33:07,149 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:33:07,149 - root - INFO - Training GP on classes: [1, 2] \r\n",
      "2022-05-11 12:33:07,169 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:07,170 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:07,170 - root - INFO - Loss: 50.55609, Avg. Loss: 0.55556\r\n",
      "2022-05-11 12:33:07,170 - root - INFO - No need for training. Class: [2] \r\n",
      "Step: 1, client: 8, Inner Step: 0, Loss: 2.631967306137085:   0%| | 0/300 [00:012022-05-11 12:33:07,982 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:33:07,982 - root - INFO - Training GP on classes: [5, 6] \r\n",
      "2022-05-11 12:33:08,004 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:08,004 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:08,004 - root - INFO - Loss: 68.36627, Avg. Loss: 0.65737\r\n",
      "2022-05-11 12:33:08,005 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:33:08,005 - root - INFO - Training GP on classes: [4, 5, 6] \r\n",
      "2022-05-11 12:33:08,031 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:08,031 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:08,031 - root - INFO - Loss: 95.16608, Avg. Loss: 0.60615\r\n",
      "2022-05-11 12:33:08,031 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:33:08,031 - root - INFO - Training GP on classes: [4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:08,067 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:08,067 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:08,067 - root - INFO - Loss: 77.80886, Avg. Loss: 0.37408\r\n",
      "2022-05-11 12:33:08,067 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:33:08,067 - root - INFO - Training GP on classes: [0, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:08,382 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:08,383 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:08,383 - root - INFO - Loss: 403.64635, Avg. Loss: 0.51354\r\n",
      "2022-05-11 12:33:08,383 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:33:08,383 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:08,830 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:08,830 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:08,830 - root - INFO - Loss: 254.24487, Avg. Loss: 0.26791\r\n",
      "2022-05-11 12:33:08,830 - root - INFO - No need for training. Class: [3] \r\n",
      "2022-05-11 12:33:08,830 - root - INFO - Training GP on classes: [1, 2, 3] \r\n",
      "2022-05-11 12:33:08,859 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:08,859 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:08,859 - root - INFO - Loss: 25.66562, Avg. Loss: 0.15746\r\n",
      "2022-05-11 12:33:08,860 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:33:08,860 - root - INFO - Training GP on classes: [1, 2] \r\n",
      "2022-05-11 12:33:08,883 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:08,883 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:08,883 - root - INFO - Loss: 59.35487, Avg. Loss: 0.54454\r\n",
      "2022-05-11 12:33:08,883 - root - INFO - No need for training. Class: [2] \r\n",
      "Step: 1, client: 8, Inner Step: 0, Loss: 3.1210532188415527:   0%| | 0/300 [00:02022-05-11 12:33:09,643 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:33:09,644 - root - INFO - Training GP on classes: [5, 6, 7] \r\n",
      "2022-05-11 12:33:09,670 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:09,670 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:09,670 - root - INFO - Loss: 69.90085, Avg. Loss: 0.44523\r\n",
      "2022-05-11 12:33:09,670 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:33:09,670 - root - INFO - Training GP on classes: [5, 6] \r\n",
      "2022-05-11 12:33:09,693 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:09,693 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:09,693 - root - INFO - Loss: 65.59405, Avg. Loss: 0.63071\r\n",
      "2022-05-11 12:33:09,693 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:33:09,694 - root - INFO - Training GP on classes: [0, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:10,017 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:10,017 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:10,017 - root - INFO - Loss: 317.71036, Avg. Loss: 0.40064\r\n",
      "2022-05-11 12:33:10,018 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:33:10,018 - root - INFO - Training GP on classes: [0, 4] \r\n",
      "2022-05-11 12:33:10,223 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:10,223 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:10,223 - root - INFO - Loss: 171.11480, Avg. Loss: 0.26905\r\n",
      "2022-05-11 12:33:10,223 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:33:10,223 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:10,673 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:10,673 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:10,674 - root - INFO - Loss: 229.68605, Avg. Loss: 0.24101\r\n",
      "2022-05-11 12:33:10,674 - root - INFO - No need for training. Class: [3] \r\n",
      "2022-05-11 12:33:10,674 - root - INFO - Training GP on classes: [1, 2, 3] \r\n",
      "2022-05-11 12:33:10,704 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:10,705 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:10,705 - root - INFO - Loss: 21.08898, Avg. Loss: 0.13264\r\n",
      "2022-05-11 12:33:10,705 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:33:10,705 - root - INFO - Training GP on classes: [1, 2] \r\n",
      "2022-05-11 12:33:10,729 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:10,730 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:10,730 - root - INFO - Loss: 44.24256, Avg. Loss: 0.42136\r\n",
      "2022-05-11 12:33:10,730 - root - INFO - No need for training. Class: [2] \r\n",
      "Step: 1, client: 8, Inner Step: 0, Loss: 2.5406389236450195:   0%| | 0/300 [00:02022-05-11 12:33:11,522 - root - INFO - No need for training. Class: [3] \r\n",
      "2022-05-11 12:33:11,522 - root - INFO - Training GP on classes: [3, 5] \r\n",
      "2022-05-11 12:33:11,543 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:11,543 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:11,543 - root - INFO - Loss: 31.66096, Avg. Loss: 0.31981\r\n",
      "2022-05-11 12:33:11,543 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:33:11,543 - root - INFO - Training GP on classes: [2, 3, 5, 6] \r\n",
      "2022-05-11 12:33:11,572 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:11,573 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:11,573 - root - INFO - Loss: 37.79852, Avg. Loss: 0.22634\r\n",
      "2022-05-11 12:33:11,573 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:33:11,573 - root - INFO - Training GP on classes: [2, 6] \r\n",
      "2022-05-11 12:33:11,592 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:11,592 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:11,592 - root - INFO - Loss: 32.34478, Avg. Loss: 0.47566\r\n",
      "2022-05-11 12:33:11,592 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:33:11,592 - root - INFO - Training GP on classes: [1, 2, 3, 5, 6] \r\n",
      "2022-05-11 12:33:11,629 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:11,630 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:11,630 - root - INFO - Loss: 65.10394, Avg. Loss: 0.30281\r\n",
      "2022-05-11 12:33:11,630 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:33:11,630 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:11,936 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:11,936 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:11,936 - root - INFO - Loss: 262.47062, Avg. Loss: 0.33955\r\n",
      "2022-05-11 12:33:11,936 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:33:11,936 - root - INFO - Training GP on classes: [4, 7] \r\n",
      "2022-05-11 12:33:11,959 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:11,960 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:11,960 - root - INFO - Loss: 11.27125, Avg. Loss: 0.12524\r\n",
      "2022-05-11 12:33:11,960 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:33:11,960 - root - INFO - Training GP on classes: [0, 4, 7] \r\n",
      "2022-05-11 12:33:12,113 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:12,113 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:12,113 - root - INFO - Loss: 140.72053, Avg. Loss: 0.25264\r\n",
      "2022-05-11 12:33:12,114 - root - INFO - No need for training. Class: [0] \r\n",
      "Step: 1, client: 1, Inner Step: 0, Loss: 2.0420377254486084:   0%| | 0/300 [00:02022-05-11 12:33:12,782 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:33:12,782 - root - INFO - Training GP on classes: [3, 4, 7] \r\n",
      "2022-05-11 12:33:12,810 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:12,810 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:12,810 - root - INFO - Loss: 6.87676, Avg. Loss: 0.04465\r\n",
      "2022-05-11 12:33:12,810 - root - INFO - No need for training. Class: [3] \r\n",
      "2022-05-11 12:33:12,810 - root - INFO - Training GP on classes: [3, 4] \r\n",
      "2022-05-11 12:33:12,841 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:12,841 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:12,841 - root - INFO - Loss: 24.24192, Avg. Loss: 0.22656\r\n",
      "2022-05-11 12:33:12,842 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:33:12,842 - root - INFO - Training GP on classes: [0, 3, 4, 7] \r\n",
      "2022-05-11 12:33:13,113 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:13,113 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:13,113 - root - INFO - Loss: 160.83402, Avg. Loss: 0.22093\r\n",
      "2022-05-11 12:33:13,113 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:33:13,113 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:13,554 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:13,554 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:13,554 - root - INFO - Loss: 184.00670, Avg. Loss: 0.19764\r\n",
      "2022-05-11 12:33:13,554 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:33:13,554 - root - INFO - Training GP on classes: [2, 6] \r\n",
      "2022-05-11 12:33:13,576 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:13,576 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:13,576 - root - INFO - Loss: 39.22522, Avg. Loss: 0.40860\r\n",
      "2022-05-11 12:33:13,576 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:33:13,576 - root - INFO - Training GP on classes: [2, 5, 6] \r\n",
      "2022-05-11 12:33:13,605 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:13,605 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:13,605 - root - INFO - Loss: 34.52558, Avg. Loss: 0.23017\r\n",
      "2022-05-11 12:33:13,605 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:33:13,605 - root - INFO - Training GP on classes: [1, 2, 5, 6] \r\n",
      "2022-05-11 12:33:13,640 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:13,640 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:13,640 - root - INFO - Loss: 64.54219, Avg. Loss: 0.31952\r\n",
      "2022-05-11 12:33:13,640 - root - INFO - No need for training. Class: [1] \r\n",
      "Step: 1, client: 1, Inner Step: 0, Loss: 1.6480666399002075:   0%| | 0/300 [00:02022-05-11 12:33:14,423 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:33:14,423 - root - INFO - Training GP on classes: [0, 7] \r\n",
      "2022-05-11 12:33:14,630 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:14,631 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:14,631 - root - INFO - Loss: 28.31599, Avg. Loss: 0.04665\r\n",
      "2022-05-11 12:33:14,631 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:33:14,631 - root - INFO - Training GP on classes: [0, 3, 4, 5, 7] \r\n",
      "2022-05-11 12:33:14,943 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:14,943 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:14,943 - root - INFO - Loss: 205.86951, Avg. Loss: 0.26495\r\n",
      "2022-05-11 12:33:14,944 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:33:14,944 - root - INFO - Training GP on classes: [4, 5] \r\n",
      "2022-05-11 12:33:14,967 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:14,968 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:14,968 - root - INFO - Loss: 51.14236, Avg. Loss: 0.45663\r\n",
      "2022-05-11 12:33:14,968 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:33:14,968 - root - INFO - Training GP on classes: [3, 4, 5] \r\n",
      "2022-05-11 12:33:14,997 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:14,997 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:14,997 - root - INFO - Loss: 18.20626, Avg. Loss: 0.10773\r\n",
      "2022-05-11 12:33:14,998 - root - INFO - No need for training. Class: [3] \r\n",
      "2022-05-11 12:33:14,998 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:15,424 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:15,425 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:15,425 - root - INFO - Loss: 63.69318, Avg. Loss: 0.06953\r\n",
      "2022-05-11 12:33:15,425 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:33:15,425 - root - INFO - Training GP on classes: [2, 6] \r\n",
      "2022-05-11 12:33:15,447 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:15,447 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:15,447 - root - INFO - Loss: 28.06731, Avg. Loss: 0.33020\r\n",
      "2022-05-11 12:33:15,447 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:33:15,447 - root - INFO - Training GP on classes: [1, 2, 6] \r\n",
      "2022-05-11 12:33:15,477 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:15,477 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:15,477 - root - INFO - Loss: 51.75753, Avg. Loss: 0.37236\r\n",
      "2022-05-11 12:33:15,477 - root - INFO - No need for training. Class: [1] \r\n",
      "Step: 1, client: 1, Inner Step: 0, Loss: 1.648055076599121:   0%| | 0/300 [00:102022-05-11 12:33:16,319 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:33:16,319 - root - INFO - Training GP on classes: [4, 7] \r\n",
      "2022-05-11 12:33:16,340 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:16,340 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:16,340 - root - INFO - Loss: 52.33713, Avg. Loss: 0.59474\r\n",
      "2022-05-11 12:33:16,340 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:33:16,340 - root - INFO - Training GP on classes: [4, 6, 7] \r\n",
      "2022-05-11 12:33:16,366 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:16,366 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:16,366 - root - INFO - Loss: 79.26058, Avg. Loss: 0.60970\r\n",
      "2022-05-11 12:33:16,367 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:33:16,368 - root - INFO - Training GP on classes: [4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:16,396 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:16,396 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:16,396 - root - INFO - Loss: 69.24600, Avg. Loss: 0.42482\r\n",
      "2022-05-11 12:33:16,397 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:33:16,397 - root - INFO - Training GP on classes: [0, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:16,615 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:16,615 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:16,615 - root - INFO - Loss: 317.07360, Avg. Loss: 0.49007\r\n",
      "2022-05-11 12:33:16,615 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:33:16,615 - root - INFO - Training GP on classes: [0, 1, 2, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:16,895 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:16,895 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:16,895 - root - INFO - Loss: 173.82218, Avg. Loss: 0.23332\r\n",
      "2022-05-11 12:33:16,896 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:33:16,896 - root - INFO - Training GP on classes: [1, 2] \r\n",
      "2022-05-11 12:33:16,918 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:16,918 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:16,918 - root - INFO - Loss: 33.33688, Avg. Loss: 0.34017\r\n",
      "2022-05-11 12:33:16,919 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:33:16,919 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:17,240 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:17,240 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:17,240 - root - INFO - Loss: 47.39276, Avg. Loss: 0.05939\r\n",
      "2022-05-11 12:33:17,241 - root - INFO - No need for training. Class: [3] \r\n",
      "Step: 1, client: 5, Inner Step: 0, Loss: 2.752206325531006:   0%| | 0/300 [00:112022-05-11 12:33:17,992 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:33:17,993 - root - INFO - Training GP on classes: [6, 7] \r\n",
      "2022-05-11 12:33:18,018 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:18,018 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:18,018 - root - INFO - Loss: 63.35954, Avg. Loss: 0.65319\r\n",
      "2022-05-11 12:33:18,018 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:33:18,019 - root - INFO - Training GP on classes: [0, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:18,288 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:18,289 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:18,289 - root - INFO - Loss: 214.83968, Avg. Loss: 0.29797\r\n",
      "2022-05-11 12:33:18,289 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:33:18,289 - root - INFO - Training GP on classes: [4, 5] \r\n",
      "2022-05-11 12:33:18,312 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:18,312 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:18,312 - root - INFO - Loss: 59.09974, Avg. Loss: 0.59697\r\n",
      "2022-05-11 12:33:18,312 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:33:18,312 - root - INFO - Training GP on classes: [0, 4, 5] \r\n",
      "2022-05-11 12:33:18,517 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:18,517 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:18,517 - root - INFO - Loss: 241.64229, Avg. Loss: 0.38787\r\n",
      "2022-05-11 12:33:18,517 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:33:18,517 - root - INFO - Training GP on classes: [0, 1, 2, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:18,857 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:18,857 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:18,857 - root - INFO - Loss: 195.61337, Avg. Loss: 0.23568\r\n",
      "2022-05-11 12:33:18,858 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:33:18,858 - root - INFO - Training GP on classes: [1, 2] \r\n",
      "2022-05-11 12:33:18,884 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:18,884 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:18,884 - root - INFO - Loss: 28.76869, Avg. Loss: 0.26393\r\n",
      "2022-05-11 12:33:18,885 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:33:18,885 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:19,275 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:19,275 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:19,275 - root - INFO - Loss: 41.45727, Avg. Loss: 0.04658\r\n",
      "2022-05-11 12:33:19,275 - root - INFO - No need for training. Class: [3] \r\n",
      "Step: 1, client: 5, Inner Step: 0, Loss: 2.482194423675537:   0%| | 0/300 [00:132022-05-11 12:33:20,136 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:33:20,136 - root - INFO - Training GP on classes: [6, 7] \r\n",
      "2022-05-11 12:33:20,159 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:20,159 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:20,159 - root - INFO - Loss: 60.89515, Avg. Loss: 0.62779\r\n",
      "2022-05-11 12:33:20,160 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:33:20,160 - root - INFO - Training GP on classes: [0, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:20,441 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:20,441 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:20,441 - root - INFO - Loss: 192.13765, Avg. Loss: 0.25550\r\n",
      "2022-05-11 12:33:20,441 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:33:20,441 - root - INFO - Training GP on classes: [0, 4, 5] \r\n",
      "2022-05-11 12:33:20,665 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:20,665 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:20,665 - root - INFO - Loss: 125.39782, Avg. Loss: 0.19174\r\n",
      "2022-05-11 12:33:20,665 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:33:20,665 - root - INFO - Training GP on classes: [0, 4] \r\n",
      "2022-05-11 12:33:20,843 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:20,844 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:20,844 - root - INFO - Loss: 173.91361, Avg. Loss: 0.28746\r\n",
      "2022-05-11 12:33:20,844 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:33:20,844 - root - INFO - Training GP on classes: [0, 1, 2, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:21,224 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:21,225 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:21,225 - root - INFO - Loss: 208.40055, Avg. Loss: 0.24120\r\n",
      "2022-05-11 12:33:21,225 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:33:21,225 - root - INFO - Training GP on classes: [1, 2] \r\n",
      "2022-05-11 12:33:21,250 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:21,250 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:21,250 - root - INFO - Loss: 28.96848, Avg. Loss: 0.25865\r\n",
      "2022-05-11 12:33:21,250 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:33:21,250 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:21,684 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:21,684 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:21,684 - root - INFO - Loss: 41.82714, Avg. Loss: 0.04522\r\n",
      "2022-05-11 12:33:21,685 - root - INFO - No need for training. Class: [3] \r\n",
      "Step: 1, client: 5, Inner Step: 0, Loss: 1.907557487487793:   0%| | 0/300 [00:162022-05-11 12:33:22,660 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:33:22,660 - root - INFO - Training GP on classes: [5, 6] \r\n",
      "2022-05-11 12:33:22,681 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:22,681 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:22,681 - root - INFO - Loss: 33.02559, Avg. Loss: 0.37529\r\n",
      "2022-05-11 12:33:22,681 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:33:22,681 - root - INFO - Training GP on classes: [4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:22,713 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:22,713 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:22,713 - root - INFO - Loss: 58.57489, Avg. Loss: 0.32907\r\n",
      "2022-05-11 12:33:22,713 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:33:22,714 - root - INFO - Training GP on classes: [4, 7] \r\n",
      "2022-05-11 12:33:22,740 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:22,740 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:22,740 - root - INFO - Loss: 19.43947, Avg. Loss: 0.21599\r\n",
      "2022-05-11 12:33:22,740 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:33:22,741 - root - INFO - Training GP on classes: [0, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:22,978 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:22,978 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:22,978 - root - INFO - Loss: 260.83001, Avg. Loss: 0.38189\r\n",
      "2022-05-11 12:33:22,978 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:33:22,978 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:23,305 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:23,306 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:23,306 - root - INFO - Loss: 106.37878, Avg. Loss: 0.12989\r\n",
      "2022-05-11 12:33:23,306 - root - INFO - No need for training. Class: [3] \r\n",
      "2022-05-11 12:33:23,306 - root - INFO - Training GP on classes: [1, 2, 3] \r\n",
      "2022-05-11 12:33:23,333 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:23,333 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:23,333 - root - INFO - Loss: 9.93058, Avg. Loss: 0.07302\r\n",
      "2022-05-11 12:33:23,333 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:33:23,333 - root - INFO - Training GP on classes: [1, 2] \r\n",
      "2022-05-11 12:33:23,355 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:23,355 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:23,355 - root - INFO - Loss: 48.61055, Avg. Loss: 0.51169\r\n",
      "2022-05-11 12:33:23,355 - root - INFO - No need for training. Class: [2] \r\n",
      "Step: 1, client: 0, Inner Step: 0, Loss: 2.016843795776367:   0%| | 0/300 [00:172022-05-11 12:33:24,232 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:33:24,232 - root - INFO - Training GP on classes: [4, 7] \r\n",
      "2022-05-11 12:33:24,257 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:24,257 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:24,257 - root - INFO - Loss: 12.70350, Avg. Loss: 0.11984\r\n",
      "2022-05-11 12:33:24,257 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:33:24,258 - root - INFO - Training GP on classes: [3, 4, 7] \r\n",
      "2022-05-11 12:33:24,287 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:24,287 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:24,287 - root - INFO - Loss: 18.15621, Avg. Loss: 0.11491\r\n",
      "2022-05-11 12:33:24,287 - root - INFO - No need for training. Class: [3] \r\n",
      "2022-05-11 12:33:24,288 - root - INFO - Training GP on classes: [0, 3, 4, 7] \r\n",
      "2022-05-11 12:33:24,564 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:24,565 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:24,565 - root - INFO - Loss: 182.26775, Avg. Loss: 0.24598\r\n",
      "2022-05-11 12:33:24,565 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:33:24,565 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:25,010 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:25,010 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:25,010 - root - INFO - Loss: 137.73282, Avg. Loss: 0.14621\r\n",
      "2022-05-11 12:33:25,010 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:33:25,010 - root - INFO - Training GP on classes: [2, 6] \r\n",
      "2022-05-11 12:33:25,034 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:25,034 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:25,034 - root - INFO - Loss: 23.26538, Avg. Loss: 0.24750\r\n",
      "2022-05-11 12:33:25,034 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:33:25,034 - root - INFO - Training GP on classes: [2, 5, 6] \r\n",
      "2022-05-11 12:33:25,063 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:25,063 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:25,063 - root - INFO - Loss: 21.90164, Avg. Loss: 0.15001\r\n",
      "2022-05-11 12:33:25,063 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:33:25,064 - root - INFO - Training GP on classes: [1, 2, 5, 6] \r\n",
      "2022-05-11 12:33:25,097 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:25,098 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:25,098 - root - INFO - Loss: 75.42125, Avg. Loss: 0.37711\r\n",
      "2022-05-11 12:33:25,098 - root - INFO - No need for training. Class: [1] \r\n",
      "Step: 1, client: 0, Inner Step: 0, Loss: 1.4015671014785767:   0%| | 0/300 [00:12022-05-11 12:33:25,864 - root - INFO - No need for training. Class: [3] \r\n",
      "2022-05-11 12:33:25,865 - root - INFO - Training GP on classes: [3, 5] \r\n",
      "2022-05-11 12:33:25,888 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:25,888 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:25,888 - root - INFO - Loss: 8.21110, Avg. Loss: 0.08130\r\n",
      "2022-05-11 12:33:25,888 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:33:25,888 - root - INFO - Training GP on classes: [0, 3, 4, 5, 7] \r\n",
      "2022-05-11 12:33:26,207 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:26,207 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:26,207 - root - INFO - Loss: 139.62430, Avg. Loss: 0.17674\r\n",
      "2022-05-11 12:33:26,208 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:33:26,208 - root - INFO - Training GP on classes: [4, 7] \r\n",
      "2022-05-11 12:33:26,232 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:26,232 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:26,232 - root - INFO - Loss: 7.82720, Avg. Loss: 0.07181\r\n",
      "2022-05-11 12:33:26,232 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:33:26,233 - root - INFO - Training GP on classes: [0, 4, 7] \r\n",
      "2022-05-11 12:33:26,478 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:26,478 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:26,478 - root - INFO - Loss: 149.71668, Avg. Loss: 0.21761\r\n",
      "2022-05-11 12:33:26,478 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:33:26,478 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:26,919 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:26,919 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:26,919 - root - INFO - Loss: 44.65210, Avg. Loss: 0.04695\r\n",
      "2022-05-11 12:33:26,919 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:33:26,919 - root - INFO - Training GP on classes: [1, 2, 6] \r\n",
      "2022-05-11 12:33:26,950 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:26,950 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:26,951 - root - INFO - Loss: 30.10821, Avg. Loss: 0.18818\r\n",
      "2022-05-11 12:33:26,951 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:33:26,951 - root - INFO - Training GP on classes: [1, 2] \r\n",
      "2022-05-11 12:33:26,976 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:26,977 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:26,977 - root - INFO - Loss: 29.79286, Avg. Loss: 0.27586\r\n",
      "2022-05-11 12:33:26,977 - root - INFO - No need for training. Class: [2] \r\n",
      "Step: 1, client: 0, Inner Step: 0, Loss: 1.0584471225738525:   0%| | 0/300 [00:22022-05-11 12:33:27,814 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:33:27,814 - root - INFO - Training GP on classes: [0, 7] \r\n",
      "2022-05-11 12:33:27,964 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:27,964 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:27,964 - root - INFO - Loss: 138.51760, Avg. Loss: 0.25277\r\n",
      "2022-05-11 12:33:27,965 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:33:27,965 - root - INFO - Training GP on classes: [0, 6, 7] \r\n",
      "2022-05-11 12:33:28,134 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:28,135 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:28,135 - root - INFO - Loss: 117.44717, Avg. Loss: 0.19906\r\n",
      "2022-05-11 12:33:28,135 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:33:28,135 - root - INFO - Training GP on classes: [0, 4, 6, 7] \r\n",
      "2022-05-11 12:33:28,345 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:28,345 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:28,345 - root - INFO - Loss: 147.04178, Avg. Loss: 0.23083\r\n",
      "2022-05-11 12:33:28,345 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:33:28,345 - root - INFO - Training GP on classes: [0, 1, 2, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:28,650 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:28,650 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:28,650 - root - INFO - Loss: 261.55306, Avg. Loss: 0.33880\r\n",
      "2022-05-11 12:33:28,650 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:33:28,650 - root - INFO - Training GP on classes: [2, 5] \r\n",
      "2022-05-11 12:33:28,674 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:28,674 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:28,674 - root - INFO - Loss: 32.28905, Avg. Loss: 0.35877\r\n",
      "2022-05-11 12:33:28,674 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:33:28,674 - root - INFO - Training GP on classes: [1, 2, 5] \r\n",
      "2022-05-11 12:33:28,704 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:28,704 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:28,704 - root - INFO - Loss: 53.29344, Avg. Loss: 0.40070\r\n",
      "2022-05-11 12:33:28,704 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:33:28,705 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:29,029 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:29,030 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:29,030 - root - INFO - Loss: 99.46582, Avg. Loss: 0.12130\r\n",
      "2022-05-11 12:33:29,030 - root - INFO - No need for training. Class: [3] \r\n",
      "Step: 1, client: 7, Inner Step: 0, Loss: 1.902235984802246:   0%| | 0/300 [00:232022-05-11 12:33:29,860 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:33:29,860 - root - INFO - Training GP on classes: [2, 5] \r\n",
      "2022-05-11 12:33:29,884 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:29,884 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:29,884 - root - INFO - Loss: 33.95283, Avg. Loss: 0.32031\r\n",
      "2022-05-11 12:33:29,884 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:33:29,885 - root - INFO - Training GP on classes: [0, 2, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:30,242 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:30,242 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:30,242 - root - INFO - Loss: 216.27355, Avg. Loss: 0.25686\r\n",
      "2022-05-11 12:33:30,242 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:33:30,242 - root - INFO - Training GP on classes: [6, 7] \r\n",
      "2022-05-11 12:33:30,265 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:30,266 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:30,266 - root - INFO - Loss: 52.49484, Avg. Loss: 0.54682\r\n",
      "2022-05-11 12:33:30,266 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:33:30,266 - root - INFO - Training GP on classes: [0, 4, 6, 7] \r\n",
      "2022-05-11 12:33:30,521 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:30,522 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:30,522 - root - INFO - Loss: 217.97285, Avg. Loss: 0.29616\r\n",
      "2022-05-11 12:33:30,522 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:33:30,522 - root - INFO - Training GP on classes: [0, 4] \r\n",
      "2022-05-11 12:33:30,731 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:30,731 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:30,731 - root - INFO - Loss: 170.74118, Avg. Loss: 0.26720\r\n",
      "2022-05-11 12:33:30,731 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:33:30,732 - root - INFO - Training GP on classes: [0, 1, 2, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:31,122 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:31,122 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:31,122 - root - INFO - Loss: 83.58046, Avg. Loss: 0.09360\r\n",
      "2022-05-11 12:33:31,122 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:33:31,122 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:31,569 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:31,569 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:31,569 - root - INFO - Loss: 83.81340, Avg. Loss: 0.08850\r\n",
      "2022-05-11 12:33:31,569 - root - INFO - No need for training. Class: [3] \r\n",
      "Step: 1, client: 7, Inner Step: 0, Loss: 1.8694465160369873:   0%| | 0/300 [00:22022-05-11 12:33:32,641 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:33:32,641 - root - INFO - Training GP on classes: [1, 2] \r\n",
      "2022-05-11 12:33:32,667 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:32,667 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:32,667 - root - INFO - Loss: 37.29170, Avg. Loss: 0.35516\r\n",
      "2022-05-11 12:33:32,668 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:33:32,668 - root - INFO - Training GP on classes: [0, 1, 2, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:33,086 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:33,086 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:33,086 - root - INFO - Loss: 125.13412, Avg. Loss: 0.13919\r\n",
      "2022-05-11 12:33:33,087 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:33:33,087 - root - INFO - Training GP on classes: [0, 4, 6, 7] \r\n",
      "2022-05-11 12:33:33,361 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:33,361 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:33,361 - root - INFO - Loss: 114.96386, Avg. Loss: 0.15599\r\n",
      "2022-05-11 12:33:33,361 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:33:33,361 - root - INFO - Training GP on classes: [0, 7] \r\n",
      "2022-05-11 12:33:33,563 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:33,563 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:33,563 - root - INFO - Loss: 149.31404, Avg. Loss: 0.23663\r\n",
      "2022-05-11 12:33:33,564 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:33:33,564 - root - INFO - Training GP on classes: [0, 4, 7] \r\n",
      "2022-05-11 12:33:33,800 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:33,801 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:33,801 - root - INFO - Loss: 164.97106, Avg. Loss: 0.24083\r\n",
      "2022-05-11 12:33:33,802 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:33:33,802 - root - INFO - Training GP on classes: [0, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:34,123 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:34,123 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:34,123 - root - INFO - Loss: 115.43587, Avg. Loss: 0.14557\r\n",
      "2022-05-11 12:33:34,124 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:33:34,124 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:33:34,582 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:33:34,582 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:33:34,582 - root - INFO - Loss: 86.40434, Avg. Loss: 0.09067\r\n",
      "2022-05-11 12:33:34,582 - root - INFO - No need for training. Class: [3] \r\n",
      "Step: 10, client: 6, Inner Step: 0, Loss: 1.3818472623825073:   3%| | 9/300 [05:2022-05-11 12:40:53,991 - root - INFO - Logger set. Log level  = INFO\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mmoshebeutel\u001B[0m (\u001B[33memg_diff_priv\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Tracking run with wandb version 0.12.16\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run data is saved locally in \u001B[35m\u001B[1m/home/user/GIT/EMG_data_analysis/p_fed_gp_emg/wandb/run-20220511_124054-1uczs47g\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Run \u001B[1m`wandb offline`\u001B[0m to turn off syncing.\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Syncing run \u001B[33mrerun_conv3d_putEMG_pFedGP-Full_run_output_lr_0.1\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: ‚≠êÔ∏è View project at \u001B[34m\u001B[4mhttps://wandb.ai/emg_diff_priv/emg_gp_moshe\u001B[0m\r\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: üöÄ View run at \u001B[34m\u001B[4mhttps://wandb.ai/emg_diff_priv/emg_gp_moshe/runs/1uczs47g\u001B[0m\r\n",
      "Denoising skipped!\r\n",
      "\r\n",
      "Feature extraction skipped!\r\n",
      "\r\n",
      "Reading features for input file:  emg_gestures-03-repeats_long-2018-05-11-11-05-00-695\r\n",
      "Reading features for input file:  emg_gestures-03-repeats_long-2018-06-14-12-32-53-659\r\n",
      "Reading features for input file:  emg_gestures-03-repeats_short-2018-05-11-11-15-21-403\r\n",
      "Reading features for input file:  emg_gestures-03-repeats_short-2018-06-14-12-43-13-875\r\n",
      "Reading features for input file:  emg_gestures-03-sequential-2018-05-11-11-10-50-475\r\n",
      "Reading features for input file:  emg_gestures-03-sequential-2018-06-14-12-38-43-358\r\n",
      "Reading features for input file:  emg_gestures-04-repeats_long-2018-03-28-12-38-01-391\r\n",
      "Reading features for input file:  emg_gestures-04-repeats_long-2018-06-18-15-02-12-970\r\n",
      "Reading features for input file:  emg_gestures-04-repeats_short-2018-03-28-12-53-43-859\r\n",
      "Reading features for input file:  emg_gestures-04-repeats_short-2018-06-18-15-12-34-944\r\n",
      "Reading features for input file:  emg_gestures-04-sequential-2018-03-28-12-49-06-858\r\n",
      "Reading features for input file:  emg_gestures-04-sequential-2018-06-18-15-08-04-934\r\n",
      "Reading features for input file:  emg_gestures-05-repeats_long-2018-04-04-08-32-11-307\r\n",
      "Exception in thread Thread-11:\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/user/GIT/IdanAchituvPutEMG/venv/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 22, in wrapper\r\n",
      "    return func(*args, **kwargs)\r\n",
      "  File \"/home/user/GIT/IdanAchituvPutEMG/venv/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 1434, in upload_urls\r\n",
      "    raise CommError(f\"Run does not exist {entity}/{project}/{run_id}.\")\r\n",
      "wandb.errors.CommError: Run does not exist emg_diff_priv/emg_gp_moshe/1uczs47g.\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\r\n",
      "Reading features for input file:  emg_gestures-05-repeats_long-2018-04-23-08-25-01-289\r\n",
      "    self.run()\r\n",
      "  File \"/home/user/GIT/IdanAchituvPutEMG/venv/lib/python3.8/site-packages/wandb/filesync/upload_job.py\", line 56, in run\r\n",
      "    success = self.push()\r\n",
      "  File \"/home/user/GIT/IdanAchituvPutEMG/venv/lib/python3.8/site-packages/wandb/filesync/upload_job.py\", line 107, in push\r\n",
      "    _, upload_headers, result = self._api.upload_urls(project, [self.save_name])\r\n",
      "  File \"/home/user/GIT/IdanAchituvPutEMG/venv/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 58, in wrapper\r\n",
      "    raise CommError(message, err).with_traceback(sys.exc_info()[2])\r\n",
      "  File \"/home/user/GIT/IdanAchituvPutEMG/venv/lib/python3.8/site-packages/wandb/apis/normalize.py\", line 22, in wrapper\r\n",
      "    return func(*args, **kwargs)\r\n",
      "  File \"/home/user/GIT/IdanAchituvPutEMG/venv/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py\", line 1434, in upload_urls\r\n",
      "    raise CommError(f\"Run does not exist {entity}/{project}/{run_id}.\")\r\n",
      "wandb.errors.CommError: Run does not exist emg_diff_priv/emg_gp_moshe/1uczs47g.\r\n",
      "Reading features for input file:  emg_gestures-05-repeats_short-2018-04-04-08-42-37-751\r\n",
      "Reading features for input file:  emg_gestures-05-repeats_short-2018-04-23-08-35-24-986\r\n",
      "Reading features for input file:  emg_gestures-05-sequential-2018-04-04-08-38-05-065\r\n",
      "Reading features for input file:  emg_gestures-05-sequential-2018-04-23-08-30-53-599\r\n",
      "Reading features for input file:  emg_gestures-06-repeats_long-2018-04-04-14-04-57-907\r\n",
      "Reading features for input file:  emg_gestures-06-repeats_long-2018-04-16-08-36-26-469\r\n",
      "Reading features for input file:  emg_gestures-06-repeats_short-2018-04-04-14-15-20-266\r\n",
      "Reading features for input file:  emg_gestures-06-repeats_short-2018-04-16-08-46-42-440\r\n",
      "Reading features for input file:  emg_gestures-06-sequential-2018-04-04-14-10-48-294\r\n",
      "Reading features for input file:  emg_gestures-06-sequential-2018-04-16-08-42-11-963\r\n",
      "Reading features for input file:  emg_gestures-07-repeats_long-2018-04-04-11-42-19-070\r\n",
      "Reading features for input file:  emg_gestures-07-repeats_long-2018-05-11-12-53-52-085\r\n",
      "Reading features for input file:  emg_gestures-07-repeats_short-2018-04-04-11-52-48-698\r\n",
      "Reading features for input file:  emg_gestures-07-repeats_short-2018-05-11-13-04-19-653\r\n",
      "Reading features for input file:  emg_gestures-07-sequential-2018-04-04-11-48-10-667\r\n",
      "Reading features for input file:  emg_gestures-07-sequential-2018-05-11-12-59-42-080\r\n",
      "2022-05-11 12:40:57,010 - root - INFO - ======================== 24chn =======================\r\n",
      "2022-05-11 12:40:57,010 - root - INFO - ======================== RMS =======================\r\n",
      "2022-05-11 12:40:57,012 - root - INFO - RawEmg3DConvnet(\r\n",
      "  (_conv1): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1))\r\n",
      "  (_pool1): AvgPool3d(kernel_size=(1, 3, 1), stride=(1, 3, 1), padding=0)\r\n",
      "  (_fc1): Linear(in_features=256, out_features=256, bias=True)\r\n",
      "  (_fc2): Linear(in_features=256, out_features=128, bias=True)\r\n",
      "  (_fc3): Linear(in_features=128, out_features=64, bias=True)\r\n",
      "  (_output): Linear(in_features=64, out_features=64, bias=True)\r\n",
      ")\r\n",
      "2022-05-11 12:40:57,012 - root - INFO - Number Parameters: 111424\r\n",
      "  0%|                                                   | 0/300 [00:00<?, ?it/s]2022-05-11 12:40:59,680 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:40:59,680 - root - INFO - Training GP on classes: [6, 7] \r\n",
      "2022-05-11 12:40:59,707 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:40:59,708 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:40:59,708 - root - INFO - Loss: 58.41003, Avg. Loss: 0.64187\r\n",
      "2022-05-11 12:40:59,708 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:40:59,708 - root - INFO - Training GP on classes: [0, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:00,002 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:00,003 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:00,003 - root - INFO - Loss: 244.08710, Avg. Loss: 0.35222\r\n",
      "2022-05-11 12:41:00,003 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:41:00,003 - root - INFO - Training GP on classes: [0, 4, 5] \r\n",
      "2022-05-11 12:41:00,177 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:00,178 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:00,179 - root - INFO - Loss: 153.67563, Avg. Loss: 0.25528\r\n",
      "2022-05-11 12:41:00,180 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:41:00,180 - root - INFO - Training GP on classes: [0, 4] \r\n",
      "2022-05-11 12:41:00,331 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:00,331 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:00,331 - root - INFO - Loss: 151.24539, Avg. Loss: 0.27105\r\n",
      "2022-05-11 12:41:00,331 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:41:00,332 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:00,667 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:00,668 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:00,668 - root - INFO - Loss: 279.24829, Avg. Loss: 0.33604\r\n",
      "2022-05-11 12:41:00,668 - root - INFO - No need for training. Class: [3] \r\n",
      "2022-05-11 12:41:00,668 - root - INFO - Training GP on classes: [1, 2, 3] \r\n",
      "2022-05-11 12:41:00,695 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:00,696 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:00,696 - root - INFO - Loss: 30.35398, Avg. Loss: 0.21996\r\n",
      "2022-05-11 12:41:00,696 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:41:00,696 - root - INFO - Training GP on classes: [1, 2] \r\n",
      "2022-05-11 12:41:00,719 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:00,719 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:00,719 - root - INFO - Loss: 50.55609, Avg. Loss: 0.55556\r\n",
      "2022-05-11 12:41:00,720 - root - INFO - No need for training. Class: [2] \r\n",
      "Step: 1, client: 8, Inner Step: 0, Loss: 2.631967306137085:   0%| | 0/300 [00:012022-05-11 12:41:01,543 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:41:01,543 - root - INFO - Training GP on classes: [4, 5] \r\n",
      "2022-05-11 12:41:01,566 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:01,566 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:01,566 - root - INFO - Loss: 68.12011, Avg. Loss: 0.65500\r\n",
      "2022-05-11 12:41:01,566 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:41:01,566 - root - INFO - Training GP on classes: [4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:01,600 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:01,600 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:01,600 - root - INFO - Loss: 123.65236, Avg. Loss: 0.59164\r\n",
      "2022-05-11 12:41:01,600 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:41:01,600 - root - INFO - Training GP on classes: [6, 7] \r\n",
      "2022-05-11 12:41:01,626 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:01,626 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:01,626 - root - INFO - Loss: 61.20829, Avg. Loss: 0.59426\r\n",
      "2022-05-11 12:41:01,627 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:41:01,627 - root - INFO - Training GP on classes: [0, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:01,940 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:01,941 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:01,941 - root - INFO - Loss: 387.11646, Avg. Loss: 0.49251\r\n",
      "2022-05-11 12:41:01,941 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:41:01,941 - root - INFO - Training GP on classes: [0, 2, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:02,295 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:02,295 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:02,295 - root - INFO - Loss: 128.01524, Avg. Loss: 0.15204\r\n",
      "2022-05-11 12:41:02,296 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:41:02,296 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:02,741 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:02,741 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:02,741 - root - INFO - Loss: 296.20442, Avg. Loss: 0.31212\r\n",
      "2022-05-11 12:41:02,742 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:41:02,742 - root - INFO - Training GP on classes: [1, 3] \r\n",
      "2022-05-11 12:41:02,764 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:02,764 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:02,765 - root - INFO - Loss: 31.68633, Avg. Loss: 0.29613\r\n",
      "2022-05-11 12:41:02,765 - root - INFO - No need for training. Class: [3] \r\n",
      "Step: 1, client: 8, Inner Step: 0, Loss: 3.093702793121338:   0%| | 0/300 [00:042022-05-11 12:41:03,763 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:41:03,763 - root - INFO - Training GP on classes: [4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:03,797 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:03,798 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:03,798 - root - INFO - Loss: 114.55206, Avg. Loss: 0.55339\r\n",
      "2022-05-11 12:41:03,798 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:41:03,798 - root - INFO - Training GP on classes: [4, 5, 7] \r\n",
      "2022-05-11 12:41:03,827 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:03,828 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:03,828 - root - INFO - Loss: 75.37448, Avg. Loss: 0.48944\r\n",
      "2022-05-11 12:41:03,828 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:41:03,828 - root - INFO - Training GP on classes: [4, 5] \r\n",
      "2022-05-11 12:41:03,851 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:03,852 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:03,852 - root - INFO - Loss: 64.81580, Avg. Loss: 0.64174\r\n",
      "2022-05-11 12:41:03,852 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:41:03,852 - root - INFO - Training GP on classes: [0, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:04,172 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:04,172 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:04,172 - root - INFO - Loss: 399.88760, Avg. Loss: 0.50364\r\n",
      "2022-05-11 12:41:04,172 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:41:04,173 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:04,620 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:04,620 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:04,620 - root - INFO - Loss: 330.14632, Avg. Loss: 0.34643\r\n",
      "2022-05-11 12:41:04,621 - root - INFO - No need for training. Class: [3] \r\n",
      "2022-05-11 12:41:04,621 - root - INFO - Training GP on classes: [1, 2, 3] \r\n",
      "2022-05-11 12:41:04,648 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:04,649 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:04,649 - root - INFO - Loss: 32.15718, Avg. Loss: 0.20225\r\n",
      "2022-05-11 12:41:04,649 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:41:04,649 - root - INFO - Training GP on classes: [1, 2] \r\n",
      "2022-05-11 12:41:04,671 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:04,671 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:04,671 - root - INFO - Loss: 57.12042, Avg. Loss: 0.54400\r\n",
      "2022-05-11 12:41:04,672 - root - INFO - No need for training. Class: [2] \r\n",
      "Step: 1, client: 8, Inner Step: 0, Loss: 3.2808923721313477:   0%| | 0/300 [00:02022-05-11 12:41:05,521 - root - INFO - No need for training. Class: [3] \r\n",
      "2022-05-11 12:41:05,521 - root - INFO - Training GP on classes: [3, 5] \r\n",
      "2022-05-11 12:41:05,543 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:05,543 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:05,543 - root - INFO - Loss: 30.33466, Avg. Loss: 0.30641\r\n",
      "2022-05-11 12:41:05,543 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:41:05,543 - root - INFO - Training GP on classes: [2, 3, 5, 6] \r\n",
      "2022-05-11 12:41:05,573 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:05,573 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:05,573 - root - INFO - Loss: 37.81589, Avg. Loss: 0.22644\r\n",
      "2022-05-11 12:41:05,574 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:41:05,574 - root - INFO - Training GP on classes: [2, 6] \r\n",
      "2022-05-11 12:41:05,592 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:05,592 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:05,592 - root - INFO - Loss: 32.73861, Avg. Loss: 0.48145\r\n",
      "2022-05-11 12:41:05,593 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:41:05,593 - root - INFO - Training GP on classes: [1, 2, 3, 5, 6] \r\n",
      "2022-05-11 12:41:05,631 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:05,631 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:05,631 - root - INFO - Loss: 68.85477, Avg. Loss: 0.32025\r\n",
      "2022-05-11 12:41:05,632 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:41:05,632 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:05,944 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:05,944 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:05,944 - root - INFO - Loss: 255.62231, Avg. Loss: 0.33069\r\n",
      "2022-05-11 12:41:05,945 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:41:05,945 - root - INFO - Training GP on classes: [4, 7] \r\n",
      "2022-05-11 12:41:05,967 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:05,967 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:05,967 - root - INFO - Loss: 11.04951, Avg. Loss: 0.12277\r\n",
      "2022-05-11 12:41:05,968 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:41:05,968 - root - INFO - Training GP on classes: [0, 4, 7] \r\n",
      "2022-05-11 12:41:06,122 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:06,122 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:06,126 - root - INFO - Loss: 156.49566, Avg. Loss: 0.28096\r\n",
      "2022-05-11 12:41:06,127 - root - INFO - No need for training. Class: [0] \r\n",
      "Step: 1, client: 1, Inner Step: 0, Loss: 2.0689806938171387:   0%| | 0/300 [00:02022-05-11 12:41:06,864 - root - INFO - No need for training. Class: [3] \r\n",
      "2022-05-11 12:41:06,864 - root - INFO - Training GP on classes: [3, 5] \r\n",
      "2022-05-11 12:41:06,895 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:06,895 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:06,895 - root - INFO - Loss: 28.00914, Avg. Loss: 0.26177\r\n",
      "2022-05-11 12:41:06,896 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:41:06,896 - root - INFO - Training GP on classes: [2, 3, 5, 6] \r\n",
      "2022-05-11 12:41:06,934 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:06,935 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:06,935 - root - INFO - Loss: 30.82366, Avg. Loss: 0.15110\r\n",
      "2022-05-11 12:41:06,935 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:41:06,935 - root - INFO - Training GP on classes: [2, 6] \r\n",
      "2022-05-11 12:41:06,956 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:06,956 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:06,957 - root - INFO - Loss: 35.92392, Avg. Loss: 0.37421\r\n",
      "2022-05-11 12:41:06,957 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:41:06,957 - root - INFO - Training GP on classes: [1, 2, 3, 5, 6] \r\n",
      "2022-05-11 12:41:07,005 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:07,005 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:07,005 - root - INFO - Loss: 70.18761, Avg. Loss: 0.27417\r\n",
      "2022-05-11 12:41:07,005 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:41:07,005 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:07,442 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:07,442 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:07,443 - root - INFO - Loss: 339.74072, Avg. Loss: 0.36531\r\n",
      "2022-05-11 12:41:07,443 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:41:07,443 - root - INFO - Training GP on classes: [4, 7] \r\n",
      "2022-05-11 12:41:07,467 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:07,467 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:07,467 - root - INFO - Loss: 8.17645, Avg. Loss: 0.08095\r\n",
      "2022-05-11 12:41:07,468 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:41:07,468 - root - INFO - Training GP on classes: [0, 4, 7] \r\n",
      "2022-05-11 12:41:07,699 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:07,699 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:07,699 - root - INFO - Loss: 193.33291, Avg. Loss: 0.28684\r\n",
      "2022-05-11 12:41:07,700 - root - INFO - No need for training. Class: [0] \r\n",
      "Step: 1, client: 1, Inner Step: 0, Loss: 1.7943534851074219:   0%| | 0/300 [00:02022-05-11 12:41:08,562 - root - INFO - No need for training. Class: [3] \r\n",
      "2022-05-11 12:41:08,562 - root - INFO - Training GP on classes: [3, 5] \r\n",
      "2022-05-11 12:41:08,587 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:08,587 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:08,587 - root - INFO - Loss: 30.15084, Avg. Loss: 0.25992\r\n",
      "2022-05-11 12:41:08,587 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:41:08,587 - root - INFO - Training GP on classes: [3, 4, 5] \r\n",
      "2022-05-11 12:41:08,618 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:08,618 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:08,618 - root - INFO - Loss: 87.83587, Avg. Loss: 0.52283\r\n",
      "2022-05-11 12:41:08,618 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:41:08,618 - root - INFO - Training GP on classes: [0, 3, 4, 5] \r\n",
      "2022-05-11 12:41:08,891 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:08,891 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:08,891 - root - INFO - Loss: 269.37915, Avg. Loss: 0.36901\r\n",
      "2022-05-11 12:41:08,892 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:41:08,892 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:09,321 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:09,321 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:09,321 - root - INFO - Loss: 109.60765, Avg. Loss: 0.11966\r\n",
      "2022-05-11 12:41:09,322 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:41:09,322 - root - INFO - Training GP on classes: [2, 6, 7] \r\n",
      "2022-05-11 12:41:09,347 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:09,347 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:09,347 - root - INFO - Loss: 18.78649, Avg. Loss: 0.14341\r\n",
      "2022-05-11 12:41:09,348 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:41:09,348 - root - INFO - Training GP on classes: [2, 6] \r\n",
      "2022-05-11 12:41:09,371 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:09,371 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:09,371 - root - INFO - Loss: 23.86767, Avg. Loss: 0.28080\r\n",
      "2022-05-11 12:41:09,371 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:41:09,371 - root - INFO - Training GP on classes: [1, 2, 6, 7] \r\n",
      "2022-05-11 12:41:09,405 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:09,406 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:09,406 - root - INFO - Loss: 92.55579, Avg. Loss: 0.49761\r\n",
      "2022-05-11 12:41:09,406 - root - INFO - No need for training. Class: [1] \r\n",
      "Step: 1, client: 1, Inner Step: 0, Loss: 2.1932411193847656:   0%| | 0/300 [00:12022-05-11 12:41:10,241 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:41:10,241 - root - INFO - Training GP on classes: [4, 7] \r\n",
      "2022-05-11 12:41:10,265 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:10,265 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:10,265 - root - INFO - Loss: 52.48047, Avg. Loss: 0.59637\r\n",
      "2022-05-11 12:41:10,265 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:41:10,265 - root - INFO - Training GP on classes: [4, 6, 7] \r\n",
      "2022-05-11 12:41:10,290 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:10,290 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:10,290 - root - INFO - Loss: 80.08566, Avg. Loss: 0.61604\r\n",
      "2022-05-11 12:41:10,291 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:41:10,291 - root - INFO - Training GP on classes: [4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:10,324 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:10,324 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:10,324 - root - INFO - Loss: 65.83010, Avg. Loss: 0.40387\r\n",
      "2022-05-11 12:41:10,324 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:41:10,324 - root - INFO - Training GP on classes: [0, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:10,544 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:10,544 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:10,544 - root - INFO - Loss: 310.56329, Avg. Loss: 0.48001\r\n",
      "2022-05-11 12:41:10,544 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:41:10,544 - root - INFO - Training GP on classes: [0, 1, 2, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:10,823 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:10,823 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:10,823 - root - INFO - Loss: 175.56466, Avg. Loss: 0.23566\r\n",
      "2022-05-11 12:41:10,823 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:41:10,823 - root - INFO - Training GP on classes: [1, 2] \r\n",
      "2022-05-11 12:41:10,845 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:10,846 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:10,846 - root - INFO - Loss: 33.67443, Avg. Loss: 0.34362\r\n",
      "2022-05-11 12:41:10,846 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:41:10,846 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:11,165 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:11,165 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:11,165 - root - INFO - Loss: 48.25859, Avg. Loss: 0.06047\r\n",
      "2022-05-11 12:41:11,166 - root - INFO - No need for training. Class: [3] \r\n",
      "Step: 1, client: 5, Inner Step: 0, Loss: 2.7360315322875977:   0%| | 0/300 [00:12022-05-11 12:41:12,020 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:41:12,020 - root - INFO - Training GP on classes: [6, 7] \r\n",
      "2022-05-11 12:41:12,044 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:12,044 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:12,044 - root - INFO - Loss: 62.20050, Avg. Loss: 0.64124\r\n",
      "2022-05-11 12:41:12,044 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:41:12,044 - root - INFO - Training GP on classes: [0, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:12,325 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:12,325 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:12,325 - root - INFO - Loss: 206.62974, Avg. Loss: 0.28659\r\n",
      "2022-05-11 12:41:12,326 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:41:12,326 - root - INFO - Training GP on classes: [4, 5] \r\n",
      "2022-05-11 12:41:12,349 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:12,349 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:12,349 - root - INFO - Loss: 59.58684, Avg. Loss: 0.60189\r\n",
      "2022-05-11 12:41:12,349 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:41:12,350 - root - INFO - Training GP on classes: [0, 4, 5] \r\n",
      "2022-05-11 12:41:12,556 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:12,556 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:12,556 - root - INFO - Loss: 230.92157, Avg. Loss: 0.37066\r\n",
      "2022-05-11 12:41:12,557 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:41:12,557 - root - INFO - Training GP on classes: [0, 1, 2, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:12,905 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:12,905 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:12,905 - root - INFO - Loss: 199.36289, Avg. Loss: 0.24020\r\n",
      "2022-05-11 12:41:12,906 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:41:12,906 - root - INFO - Training GP on classes: [1, 2] \r\n",
      "2022-05-11 12:41:12,929 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:12,929 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:12,929 - root - INFO - Loss: 22.54285, Avg. Loss: 0.20682\r\n",
      "2022-05-11 12:41:12,929 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:41:12,930 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:13,329 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:13,329 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:13,329 - root - INFO - Loss: 35.83755, Avg. Loss: 0.04027\r\n",
      "2022-05-11 12:41:13,329 - root - INFO - No need for training. Class: [3] \r\n",
      "Step: 1, client: 5, Inner Step: 0, Loss: 2.3876564502716064:   0%| | 0/300 [00:12022-05-11 12:41:14,301 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:41:14,301 - root - INFO - Training GP on classes: [6, 7] \r\n",
      "2022-05-11 12:41:14,324 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:14,324 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:14,324 - root - INFO - Loss: 60.67017, Avg. Loss: 0.62547\r\n",
      "2022-05-11 12:41:14,324 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:41:14,324 - root - INFO - Training GP on classes: [0, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:14,607 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:14,607 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:14,607 - root - INFO - Loss: 188.79583, Avg. Loss: 0.25106\r\n",
      "2022-05-11 12:41:14,608 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:41:14,608 - root - INFO - Training GP on classes: [4, 5] \r\n",
      "2022-05-11 12:41:14,631 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:14,631 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:14,631 - root - INFO - Loss: 59.05397, Avg. Loss: 0.53685\r\n",
      "2022-05-11 12:41:14,632 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:41:14,632 - root - INFO - Training GP on classes: [0, 4, 5] \r\n",
      "2022-05-11 12:41:14,860 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:14,860 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:14,860 - root - INFO - Loss: 245.63884, Avg. Loss: 0.37559\r\n",
      "2022-05-11 12:41:14,860 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:41:14,860 - root - INFO - Training GP on classes: [0, 1, 2, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:15,237 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:15,237 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:15,237 - root - INFO - Loss: 198.33127, Avg. Loss: 0.22955\r\n",
      "2022-05-11 12:41:15,238 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:41:15,238 - root - INFO - Training GP on classes: [1, 2] \r\n",
      "2022-05-11 12:41:15,264 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:15,264 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:15,264 - root - INFO - Loss: 22.67465, Avg. Loss: 0.20245\r\n",
      "2022-05-11 12:41:15,264 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:41:15,264 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:15,707 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:15,707 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:15,707 - root - INFO - Loss: 44.15779, Avg. Loss: 0.04774\r\n",
      "2022-05-11 12:41:15,708 - root - INFO - No need for training. Class: [3] \r\n",
      "Step: 1, client: 5, Inner Step: 0, Loss: 2.2687132358551025:   0%| | 0/300 [00:12022-05-11 12:41:16,726 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:41:16,727 - root - INFO - Training GP on classes: [5, 6] \r\n",
      "2022-05-11 12:41:16,749 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:16,749 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:16,749 - root - INFO - Loss: 33.40420, Avg. Loss: 0.37959\r\n",
      "2022-05-11 12:41:16,750 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:41:16,750 - root - INFO - Training GP on classes: [4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:16,782 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:16,782 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:16,782 - root - INFO - Loss: 59.59194, Avg. Loss: 0.33479\r\n",
      "2022-05-11 12:41:16,783 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:41:16,783 - root - INFO - Training GP on classes: [4, 7] \r\n",
      "2022-05-11 12:41:16,805 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:16,805 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:16,805 - root - INFO - Loss: 19.85061, Avg. Loss: 0.22056\r\n",
      "2022-05-11 12:41:16,805 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:41:16,806 - root - INFO - Training GP on classes: [0, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:17,043 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:17,043 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:17,043 - root - INFO - Loss: 251.72991, Avg. Loss: 0.36857\r\n",
      "2022-05-11 12:41:17,044 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:41:17,044 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:17,368 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:17,368 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:17,368 - root - INFO - Loss: 105.92411, Avg. Loss: 0.12933\r\n",
      "2022-05-11 12:41:17,369 - root - INFO - No need for training. Class: [3] \r\n",
      "2022-05-11 12:41:17,369 - root - INFO - Training GP on classes: [1, 2, 3] \r\n",
      "2022-05-11 12:41:17,395 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:17,396 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:17,396 - root - INFO - Loss: 10.28406, Avg. Loss: 0.07562\r\n",
      "2022-05-11 12:41:17,396 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:41:17,396 - root - INFO - Training GP on classes: [1, 2] \r\n",
      "2022-05-11 12:41:17,418 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:17,419 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:17,419 - root - INFO - Loss: 49.28346, Avg. Loss: 0.51877\r\n",
      "2022-05-11 12:41:17,420 - root - INFO - No need for training. Class: [2] \r\n",
      "Step: 1, client: 0, Inner Step: 0, Loss: 2.027231454849243:   0%| | 0/300 [00:182022-05-11 12:41:18,190 - root - INFO - No need for training. Class: [3] \r\n",
      "2022-05-11 12:41:18,190 - root - INFO - Training GP on classes: [3, 5] \r\n",
      "2022-05-11 12:41:18,214 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:18,214 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:18,214 - root - INFO - Loss: 28.33949, Avg. Loss: 0.27514\r\n",
      "2022-05-11 12:41:18,214 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:41:18,215 - root - INFO - Training GP on classes: [2, 3, 5, 6] \r\n",
      "2022-05-11 12:41:18,252 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:18,252 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:18,252 - root - INFO - Loss: 35.20405, Avg. Loss: 0.17870\r\n",
      "2022-05-11 12:41:18,253 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:41:18,253 - root - INFO - Training GP on classes: [2, 6] \r\n",
      "2022-05-11 12:41:18,275 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:18,276 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:18,276 - root - INFO - Loss: 38.11145, Avg. Loss: 0.40544\r\n",
      "2022-05-11 12:41:18,277 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:41:18,277 - root - INFO - Training GP on classes: [1, 2, 3, 5, 6] \r\n",
      "2022-05-11 12:41:18,322 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:18,322 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:18,322 - root - INFO - Loss: 88.85329, Avg. Loss: 0.35400\r\n",
      "2022-05-11 12:41:18,322 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:41:18,322 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:18,775 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:18,775 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:18,775 - root - INFO - Loss: 253.67525, Avg. Loss: 0.26929\r\n",
      "2022-05-11 12:41:18,776 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:41:18,776 - root - INFO - Training GP on classes: [4, 7] \r\n",
      "2022-05-11 12:41:18,800 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:18,800 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:18,800 - root - INFO - Loss: 19.44159, Avg. Loss: 0.18341\r\n",
      "2022-05-11 12:41:18,800 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:41:18,800 - root - INFO - Training GP on classes: [0, 4, 7] \r\n",
      "2022-05-11 12:41:19,044 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:19,044 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:19,044 - root - INFO - Loss: 192.26413, Avg. Loss: 0.27864\r\n",
      "2022-05-11 12:41:19,044 - root - INFO - No need for training. Class: [0] \r\n",
      "Step: 1, client: 0, Inner Step: 0, Loss: 1.9446287155151367:   0%| | 0/300 [00:22022-05-11 12:41:20,086 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:41:20,086 - root - INFO - Training GP on classes: [4, 7] \r\n",
      "2022-05-11 12:41:20,110 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:20,111 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:20,111 - root - INFO - Loss: 36.98216, Avg. Loss: 0.33929\r\n",
      "2022-05-11 12:41:20,111 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:41:20,111 - root - INFO - Training GP on classes: [3, 4, 7] \r\n",
      "2022-05-11 12:41:20,140 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:20,141 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:20,141 - root - INFO - Loss: 20.82941, Avg. Loss: 0.13100\r\n",
      "2022-05-11 12:41:20,141 - root - INFO - No need for training. Class: [3] \r\n",
      "2022-05-11 12:41:20,141 - root - INFO - Training GP on classes: [0, 3, 4, 7] \r\n",
      "2022-05-11 12:41:20,417 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:20,418 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:20,418 - root - INFO - Loss: 249.97061, Avg. Loss: 0.33826\r\n",
      "2022-05-11 12:41:20,418 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:41:20,418 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:20,862 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:20,863 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:20,863 - root - INFO - Loss: 229.00655, Avg. Loss: 0.24081\r\n",
      "2022-05-11 12:41:20,863 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:41:20,863 - root - INFO - Training GP on classes: [5, 6] \r\n",
      "2022-05-11 12:41:20,888 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:20,888 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:20,888 - root - INFO - Loss: 38.04223, Avg. Loss: 0.36934\r\n",
      "2022-05-11 12:41:20,888 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:41:20,889 - root - INFO - Training GP on classes: [1, 2, 5, 6] \r\n",
      "2022-05-11 12:41:20,929 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:20,929 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:20,929 - root - INFO - Loss: 59.06535, Avg. Loss: 0.27861\r\n",
      "2022-05-11 12:41:20,929 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:41:20,929 - root - INFO - Training GP on classes: [1, 2] \r\n",
      "2022-05-11 12:41:20,951 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:20,952 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:20,952 - root - INFO - Loss: 54.15265, Avg. Loss: 0.50141\r\n",
      "2022-05-11 12:41:20,952 - root - INFO - No need for training. Class: [2] \r\n",
      "Step: 1, client: 0, Inner Step: 0, Loss: 2.1987154483795166:   0%| | 0/300 [00:22022-05-11 12:41:21,834 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:41:21,835 - root - INFO - Training GP on classes: [0, 7] \r\n",
      "2022-05-11 12:41:21,986 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:21,986 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:21,986 - root - INFO - Loss: 139.02349, Avg. Loss: 0.25369\r\n",
      "2022-05-11 12:41:21,987 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:41:21,987 - root - INFO - Training GP on classes: [0, 6, 7] \r\n",
      "2022-05-11 12:41:22,161 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:22,161 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:22,161 - root - INFO - Loss: 115.18248, Avg. Loss: 0.19522\r\n",
      "2022-05-11 12:41:22,162 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:41:22,162 - root - INFO - Training GP on classes: [0, 4, 6, 7] \r\n",
      "2022-05-11 12:41:22,374 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:22,374 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:22,374 - root - INFO - Loss: 146.30918, Avg. Loss: 0.22968\r\n",
      "2022-05-11 12:41:22,375 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:41:22,375 - root - INFO - Training GP on classes: [0, 1, 2, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:22,684 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:22,684 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:22,684 - root - INFO - Loss: 258.92697, Avg. Loss: 0.33540\r\n",
      "2022-05-11 12:41:22,684 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:41:22,684 - root - INFO - Training GP on classes: [2, 5] \r\n",
      "2022-05-11 12:41:22,708 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:22,708 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:22,708 - root - INFO - Loss: 32.44107, Avg. Loss: 0.36046\r\n",
      "2022-05-11 12:41:22,709 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:41:22,709 - root - INFO - Training GP on classes: [1, 2, 5] \r\n",
      "2022-05-11 12:41:22,736 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:22,737 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:22,737 - root - INFO - Loss: 51.92723, Avg. Loss: 0.39043\r\n",
      "2022-05-11 12:41:22,737 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:41:22,737 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:23,065 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:23,065 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:23,065 - root - INFO - Loss: 98.75520, Avg. Loss: 0.12043\r\n",
      "2022-05-11 12:41:23,065 - root - INFO - No need for training. Class: [3] \r\n",
      "Step: 1, client: 7, Inner Step: 0, Loss: 1.8853192329406738:   0%| | 0/300 [00:22022-05-11 12:41:24,022 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:41:24,022 - root - INFO - Training GP on classes: [2, 5] \r\n",
      "2022-05-11 12:41:24,048 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:24,048 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:24,048 - root - INFO - Loss: 31.64510, Avg. Loss: 0.29854\r\n",
      "2022-05-11 12:41:24,048 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:41:24,049 - root - INFO - Training GP on classes: [0, 2, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:24,408 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:24,408 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:24,408 - root - INFO - Loss: 253.60875, Avg. Loss: 0.30120\r\n",
      "2022-05-11 12:41:24,409 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:41:24,409 - root - INFO - Training GP on classes: [0, 4] \r\n",
      "2022-05-11 12:41:24,624 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:24,624 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:24,624 - root - INFO - Loss: 167.68857, Avg. Loss: 0.26242\r\n",
      "2022-05-11 12:41:24,624 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:41:24,624 - root - INFO - Training GP on classes: [0, 4, 6, 7] \r\n",
      "2022-05-11 12:41:24,886 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:24,886 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:24,886 - root - INFO - Loss: 220.84046, Avg. Loss: 0.30005\r\n",
      "2022-05-11 12:41:24,887 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:41:24,887 - root - INFO - Training GP on classes: [6, 7] \r\n",
      "2022-05-11 12:41:24,910 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:24,910 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:24,910 - root - INFO - Loss: 52.50649, Avg. Loss: 0.54694\r\n",
      "2022-05-11 12:41:24,910 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:41:24,910 - root - INFO - Training GP on classes: [0, 1, 2, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:25,308 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:25,308 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:25,308 - root - INFO - Loss: 89.09247, Avg. Loss: 0.09977\r\n",
      "2022-05-11 12:41:25,308 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:41:25,309 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:25,756 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:25,756 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:25,757 - root - INFO - Loss: 70.58260, Avg. Loss: 0.07453\r\n",
      "2022-05-11 12:41:25,757 - root - INFO - No need for training. Class: [3] \r\n",
      "Step: 1, client: 7, Inner Step: 0, Loss: 1.883458137512207:   0%| | 0/300 [00:272022-05-11 12:41:27,016 - root - INFO - No need for training. Class: [6] \r\n",
      "2022-05-11 12:41:27,016 - root - INFO - Training GP on classes: [0, 4, 6, 7] \r\n",
      "2022-05-11 12:41:27,293 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:27,293 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:27,293 - root - INFO - Loss: 118.69787, Avg. Loss: 0.16106\r\n",
      "2022-05-11 12:41:27,294 - root - INFO - No need for training. Class: [0] \r\n",
      "2022-05-11 12:41:27,294 - root - INFO - Training GP on classes: [0, 7] \r\n",
      "2022-05-11 12:41:27,501 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:27,501 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:27,502 - root - INFO - Loss: 164.01838, Avg. Loss: 0.25993\r\n",
      "2022-05-11 12:41:27,502 - root - INFO - No need for training. Class: [7] \r\n",
      "2022-05-11 12:41:27,502 - root - INFO - Training GP on classes: [0, 4, 7] \r\n",
      "2022-05-11 12:41:27,745 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:27,746 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:27,746 - root - INFO - Loss: 163.75426, Avg. Loss: 0.23906\r\n",
      "2022-05-11 12:41:27,746 - root - INFO - No need for training. Class: [4] \r\n",
      "2022-05-11 12:41:27,746 - root - INFO - Training GP on classes: [0, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:28,072 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:28,072 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:28,072 - root - INFO - Loss: 141.05457, Avg. Loss: 0.17787\r\n",
      "2022-05-11 12:41:28,073 - root - INFO - No need for training. Class: [5] \r\n",
      "2022-05-11 12:41:28,073 - root - INFO - Training GP on classes: [0, 1, 2, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:28,496 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:28,497 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:28,497 - root - INFO - Loss: 156.30010, Avg. Loss: 0.17386\r\n",
      "2022-05-11 12:41:28,497 - root - INFO - No need for training. Class: [1] \r\n",
      "2022-05-11 12:41:28,497 - root - INFO - Training GP on classes: [1, 2] \r\n",
      "2022-05-11 12:41:28,522 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:28,522 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:28,522 - root - INFO - Loss: 48.62650, Avg. Loss: 0.46311\r\n",
      "2022-05-11 12:41:28,522 - root - INFO - No need for training. Class: [2] \r\n",
      "2022-05-11 12:41:28,523 - root - INFO - Training GP on classes: [0, 1, 2, 3, 4, 5, 6, 7] \r\n",
      "2022-05-11 12:41:28,993 - root - INFO - output scale: 8.0\r\n",
      "2022-05-11 12:41:28,993 - root - INFO - length scale: 1.0\r\n",
      "2022-05-11 12:41:28,993 - root - INFO - Loss: 84.33204, Avg. Loss: 0.08849\r\n",
      "2022-05-11 12:41:28,993 - root - INFO - No need for training. Class: [3] \r\n",
      "Step: 10, client: 6, Inner Step: 0, Loss: 1.5104864835739136:   3%| | 9/300 [05:CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "2022-05-11 12:51:42,099 - root - INFO - Step: 10, Test Loss: 2.0477,  Test Acc: 0.8171\r\n",
      "Step: 20, client: 7, Inner Step: 0, Loss: 1.3786145448684692:   6%| | 19/300 [162022-05-11 13:02:37,879 - root - INFO - Step: 20, Test Loss: 1.9970,  Test Acc: 0.8285\r\n",
      "Step: 30, client: 0, Inner Step: 0, Loss: 0.3233090043067932:  10%| | 29/300 [27CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: out of memory (3) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n",
      "CUBLAS error: not initialized (1) in magma_spotrf_lg_batched at /opt/conda/conda-bld/magma-cuda102_1583546904148/work/src/spotrf_batched.cpp:63\r\n"
     ]
    }
   ],
   "source": [
    "for l in [ 0.01, 0.1]:\n",
    "    !python3 trainer.py --lr $l --backbone conv3d --backbone-output 64 --depthwise-multiplier 32 --num-steps 300 --eval-every 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3810jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "language": "python",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}